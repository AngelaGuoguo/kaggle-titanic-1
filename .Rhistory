new
new[2]
new[2, ]
new[,2]
new[,c(2,5)]
new
new
new
new <- ddply(train, "pclass", transform, fare_avg = fare - mean(fare))
new
new <- ddply(train, "pclass", transform, fare_avg = mean(fare))
new2 <- trainsform(train, fare_distance = fare - fare_avg)
new2 <- transform(train, fare_distance = fare - fare_avg)
new2 <- transform(new, fare_distance = fare - fare_avg)
new2
train <- new2[, -fare_avg]
new <- ddply(train, "pclass", transform, fare_avg = mean(fare))
new2 <- transform(new, fare_distance = fare - fare_avg)
train <- new2[, -fare_avg]
train <- new2[-fare_avg, ]
train <- new2[, !fare_avg]
train <- new2[, -"fare_avg"]
new2[, 5]
head(new2[, 8])
head(new2[, 9])
head(new2[, 10])
head(new2[, 11])
head(new2[, 12])
train <- new2[, -12]
str(train)
qplot(train$fare_distance)
library(ggplot2)
install.packages('ggplot2')
library(ggplot2)
qplot(train$fare_distance)
qplot(train$fare_distance, fill = survived)
qplot(train$fare_distance, fill = train$survived)
qplot(train$fare_distance) + facet_wrap(~ train$survived)
qplot(train$fare_distance) + facet_wrap(~ survived)
qplot(train$fare_distance) + facet_wrap(~ train$survived)
qplot(train$fare_distance) + facet_wrap(train$survived)
qplot(train$fare_distance) + facet_wrap(train$survived ~)
qplot(fare_distance, data = train) + facet_wrap(~ survived)
# Goal: (1) Combine our three models into one prediction:
#             - randomForest
#             - SVM
#             - probit
# Source our models
source("2-randomForest.R")
source("3-SVM.R")
source("4-probit.R")
###
### Gather predictions
###
# randomForest
test$survived_rf <- predict(forest, test)
# SVM
test$survived_svm <- predict(svm.model, test, type = "response")
# Probit
test$survived_probit <- predict(probit, test)
test$survived_probit[test$survived >= 0.5] <- 2
test$survived_probit[test$survived < 0.5] <- 1
###
### Combine Predictions
###
combined <- as.numeric(test$survived_rf) +
as.numeric(test$survived_svm) +
as.numeric(test$survived_probit)
# 3 is 0
# 4 is 0
# 5 is 1
# 6 is 1
combined[combined <= 4] <- 0
combined[combined >= 5] <- 1
# Make our ensamble prediction
test$survived <- combined
write.csv(test, "Submissions/ensemble-01.csv")
install.packages('randomForest')
install.packages('kernlab')
library(randomForest)
library(kernlab)
# Goal: (1) Combine our three models into one prediction:
#             - randomForest
#             - SVM
#             - probit
# Source our models
source("2-randomForest.R")
source("3-SVM.R")
source("4-probit.R")
###
### Gather predictions
###
# randomForest
test$survived_rf <- predict(forest, test)
# SVM
test$survived_svm <- predict(svm.model, test, type = "response")
# Probit
test$survived_probit <- predict(probit, test)
test$survived_probit[test$survived >= 0.5] <- 2
test$survived_probit[test$survived < 0.5] <- 1
###
### Combine Predictions
###
combined <- as.numeric(test$survived_rf) +
as.numeric(test$survived_svm) +
as.numeric(test$survived_probit)
# 3 is 0
# 4 is 0
# 5 is 1
# 6 is 1
combined[combined <= 4] <- 0
combined[combined >= 5] <- 1
# Make our ensamble prediction
test$survived <- combined
write.csv(test, "Submissions/ensemble-01.csv")
new <- ddply(test, "pclass", transform, fare_avg = mean(fare))
new2 <- transform(new, fare_distance = fare - fare_avg)
new2[, -12]
str(train)
# Goal:     (1) Construct basic randomForest models from the data
#           (2) Select the best model (Model selection)
#           (3) Save a prediction with our best randomForest
library(randomForest)
library(plyr)
# Load in the cleaned data sets
load("Data/train_clean.RData")  # 891 obs
load("Data/test_clean.RData")   # 418 obs
###
### Create randomForest model
###
# Create random forest based on PCLASS, SEX, and FARE
forest <- randomForest(survived ~ sex + pclass + fare + age,
data = train, ntree = 15000, importance = TRUE)
summary(forest)
# Extract the importance of each variable
importance(forest)
age.rf <- randomForest(age ~ pclass + sex +
sibsp + parch + fare, data = full,
ntree = 15000, importance = TRUE)
?rfImpute
age.imputed <- rfImpute(age ~ ., data = full)
data(iris)
iris.na <- iris
for (i in 1:4) iris.na[sample(150, sample(20)), i] <- NA
iris.na
full.age-na <- full[!is.na(age), ]
full.age <- full[!is.na(full$age), ]
summary(full.age$age)
summary(full$age)
full.fare <- full[!is.na(full$fare), ]
age.rf <- randomForest(age ~ ., data = full.age,
ntree = 15000, importance = TRUE)
age.rf <- randomForest(age ~ . - fare, data = full.age,
ntree = 15000, importance = TRUE)
age.rf <- randomForest(age ~ pclass, data = full.age,
ntree = 15000, importance = TRUE)
age.rf <- randomForest(age ~ . -fare, data = full.age,
ntree = 1000, importance = TRUE)
is.na(full)
age.rf <- randomForest(age ~ pcass + sex + sibsp + parch + fare, data = full.age,
ntree = 1000, importance = TRUE)
age.rf <- randomForest(age ~ pclass + sex + sibsp + parch + fare, data = full.age,
ntree = 1000, importance = TRUE)
age.rf <- randomForest(age ~ pclass + sex + sibsp + parch, data = full.age,
ntree = 1000, importance = TRUE)
age.rf <- randomForest(age ~ . - fare - survived, data = full.age,
ntree = 1000, importance = TRUE)
str(full.age)
age.rf <- randomForest(age ~ pclass + sex + sibsp + parch + fare + embarked, data = full.age,
ntree = 1000, importance = TRUE)
# Create random forest based on PCLASS, SEX, and FARE
forest <- randomForest(survived ~ sex + pclass + fare + age + fare_distance,
data = train, ntree = 15000, importance = TRUE)
# Goal:     (1) Construct basic randomForest models from the data
#           (2) Select the best model (Model selection)
#           (3) Save a prediction with our best randomForest
library(randomForest)
library(plyr)
# Load in the cleaned data sets
load("Data/train_clean.RData")  # 891 obs
load("Data/test_clean.RData")   # 418 obs
###
### Create randomForest model
###
# Create random forest based on PCLASS, SEX, and FARE
forest <- randomForest(survived ~ sex + pclass + fare + age + fare_distance,
data = train, ntree = 15000, importance = TRUE)
class1 <- subset(full, pclass == 1)
fare1 <- mean(class1$fare)
class1 <- subset(full, pclass == 1)
class2 <- subset(full, pclass == 2)
class3 <- subset(full, pclass == 3)
fare1 <- mean(class1$fare)
fare2 <- mean(class2$fare)
fare3 <- mean(class3$fare)
fare1
fare2
fare3
?mean
class1 <- subset(full, pclass == 1)
class2 <- subset(full, pclass == 2)
class3 <- subset(full, pclass == 3)
fare1 <- mean(class1$fare, na.rm = TRUE)
fare2 <- mean(class2$fare, na.rm = TRUE)
fare3 <- mean(class3$fare, na.rm = TRUE)
fare1
fare2
fare3
new <- train
train[pclass == 1]$fare_avg
train[train$pclass == 1]$fare_avg
train$fare_avg[train$pclass == 1]
train$fare_avg[train$pclass == 1] <- fare1
# Goal:         (1) Fix missing values
#               (2) Fix data structures
#               (3) Save new cleaned data sets
#
# Output:       (1) R datasets (maintains data structure)
#                   - test_clean.RData
#                   - train_clean.RData
#               (2) CSV datasets (archival)
#                   - train_clean.csv
#                   - test_clean.csv
#                   - full.csv
library(plyr)
# Load the data sets
train <- read.csv("Data/train.csv", stringsAsFactors = FALSE)  # 891 obs
test <- read.csv("Data/test.csv", stringsAsFactors = FALSE)    # 418 obs
###
### Data structures
###
# Create a survived variable in the test data set
# Set "0" (did not survive) as the default value
test$survived <- 0
# Convert catagorical variables to factors
train$survived <- factor(train$survived)
train$sex <- factor(train$sex)
train$pclass <- factor(train$pclass)
train$embarked <- factor(train$embarked)
test$survived <- factor(test$survived)
test$sex <- factor(test$sex)
test$pclass <- factor(test$pclass)
test$embarked <- factor(test$embarked)
###
### Fixing missing values
###
# Combine the data sets for age/fare modeling
full <- join(test, train, type = "full")
# Remove NA's in AGE and FARE
full.age <- full[!is.na(full$age), ]
full.fare <- full[!is.na(full$fare), ]
# Create LM models for predicting missing values in AGE and FARE
age.mod <- lm(age ~ pclass + sex +
sibsp + parch + fare, data = full)
fare.mod<- lm(fare ~ pclass + sex +
sibsp + parch + age, data = full)
# Create RF models for predicting missing values in AGE and FARE
#age.rf <- randomForest(age ~ pclass + sex + sibsp + parch + fare + embarked, data = full.age,
ntree = 1000, importance = TRUE)
# Replace missing values in AGE and FARE with prediction
train$age[is.na(train$age)] <- predict(age.mod, train)
train$fare[is.na(train$fare)] <- predict(fare.mod, train)
test$age[is.na(test$age)] <- predict(age.mod, test)
test$fare[is.na(test$fare)] <- predict(fare.mod, test)
# Replace missing values in embarked with most popular
train$embarked[train$embarked == ""] <- "S"
###
### Create fare-distance metric
###
# fare-distance = fare - mean(fare of pclass)
# Are those who pay less than the average for a ticket less likely to survive?
# Find the mean fare for each pclass
class1 <- subset(full, pclass == 1)
class2 <- subset(full, pclass == 2)
class3 <- subset(full, pclass == 3)
fare1 <- mean(class1$fare, na.rm = TRUE)
fare2 <- mean(class2$fare, na.rm = TRUE)
fare3 <- mean(class3$fare, na.rm = TRUE)
# Create fare_avg column
train$fare_avg[train$pclass == 1] <- fare1
train$fare_avg[train$pclass == 2] <- fare2
train$fare_avg[train$pclass == 3] <- fare3
test$fare_avg[test$pclass == 1] <- fare1
test$fare_avg[test$pclass == 2] <- fare2
test$fare_avg[test$pclass == 3] <- fare3
# Create fare-distance metric for Train
train <- transform(train, fare_distance = fare - fare_avg)
train <- new2[, !names(train) %in% "fare_avg"]
head(train)
train <- new2[, !names(train) %in% c("fare_avg")]
head(train)
train <- train[, !names(train) %in% c("fare_avg")]
head(train)
# Create fare-distance metric for Test
test <- transform(test, fare_distance = fare - fare_avg)
test <- test[, !names(test) %in% c("fare_avg")]
###
### Saving new data sets
###
# Save files as RData in order to preserve data structures
# Open .RData with load()
save("test", file = "Data/test_clean.RData")
save("train", file = "Data/train_clean.RData")
so don't use them in the analysis!
write.csv(test, "Data/CSV/test_clean.csv", row.names = FALSE)
write.csv(train, "Data/CSV/train_clean.csv", row.names = FALSE)
write.csv(full, "Data/CSV/full.csv", row.names = FALSE)
# Goal:     (1) Construct basic randomForest models from the data
#           (2) Select the best model (Model selection)
#           (3) Save a prediction with our best randomForest
library(randomForest)
library(plyr)
# Load in the cleaned data sets
load("Data/train_clean.RData")  # 891 obs
load("Data/test_clean.RData")   # 418 obs
###
### Create randomForest model
###
# Create random forest based on PCLASS, SEX, and FARE
forest <- randomForest(survived ~ sex + pclass + fare + age + fare_distance,
data = train, ntree = 15000, importance = TRUE)
?randomForest
str(train)
# Goal:         (1) Fix missing values
#               (2) Fix data structures
#               (3) Save new cleaned data sets
#
# Output:       (1) R datasets (maintains data structure)
#                   - test_clean.RData
#                   - train_clean.RData
#               (2) CSV datasets (archival)
#                   - train_clean.csv
#                   - test_clean.csv
#                   - full.csv
library(plyr)
# Load the data sets
train <- read.csv("Data/train.csv", stringsAsFactors = FALSE)  # 891 obs
test <- read.csv("Data/test.csv", stringsAsFactors = FALSE)    # 418 obs
###
### Data structures
###
# Create a survived variable in the test data set
# Set "0" (did not survive) as the default value
test$survived <- 0
# Convert catagorical variables to factors
train$survived <- factor(train$survived)
train$sex <- factor(train$sex)
train$pclass <- factor(train$pclass)
train$embarked <- factor(train$embarked)
test$survived <- factor(test$survived)
test$sex <- factor(test$sex)
test$pclass <- factor(test$pclass)
test$embarked <- factor(test$embarked)
###
### Fixing missing values
###
# Combine the data sets for age/fare modeling
full <- join(test, train, type = "full")
# Remove NA's in AGE and FARE
full.age <- full[!is.na(full$age), ]
full.fare <- full[!is.na(full$fare), ]
# Create LM models for predicting missing values in AGE and FARE
age.mod <- lm(age ~ pclass + sex +
sibsp + parch + fare, data = full)
fare.mod<- lm(fare ~ pclass + sex +
sibsp + parch + age, data = full)
# Create RF models for predicting missing values in AGE and FARE
#age.rf <- randomForest(age ~ pclass + sex + sibsp + parch + fare + embarked, data = full.age,
ntree = 1000, importance = TRUE)
# Replace missing values in AGE and FARE with prediction
train$age[is.na(train$age)] <- predict(age.mod, train)
train$fare[is.na(train$fare)] <- predict(fare.mod, train)
test$age[is.na(test$age)] <- predict(age.mod, test)
test$fare[is.na(test$fare)] <- predict(fare.mod, test)
# Replace missing values in embarked with most popular
train$embarked[train$embarked == ""] <- "S"
###
### Create fare-distance metric
###
# fare-distance = fare - mean(fare of pclass)
# Are those who pay less than the average for a ticket less likely to survive?
# Find the mean fare for each pclass
class1 <- subset(full, pclass == 1)
class2 <- subset(full, pclass == 2)
class3 <- subset(full, pclass == 3)
fare1 <- mean(class1$fare, na.rm = TRUE)
fare2 <- mean(class2$fare, na.rm = TRUE)
fare3 <- mean(class3$fare, na.rm = TRUE)
# Create fare_avg column
train$fare_avg[train$pclass == 1] <- fare1
train$fare_avg[train$pclass == 2] <- fare2
train$fare_avg[train$pclass == 3] <- fare3
test$fare_avg[test$pclass == 1] <- fare1
test$fare_avg[test$pclass == 2] <- fare2
test$fare_avg[test$pclass == 3] <- fare3
# Create fare-distance metric for Train
train <- transform(train, fare_distance = fare - fare_avg)
train <- train[, !names(train) %in% c("fare_avg")]
# Create fare-distance metric for Test
test <- transform(test, fare_distance = fare - fare_avg)
test <- test[, !names(test) %in% c("fare_avg")]
###
### Saving new data sets
###
# Save files as RData in order to preserve data structures
# Open .RData with load()
save("test", file = "Data/test_clean.RData")
save("train", file = "Data/train_clean.RData")
# Also save .csv's just in case. These do not preserve data structures,
# so don't use them in the analysis!
write.csv(test, "Data/CSV/test_clean.csv", row.names = FALSE)
write.csv(train, "Data/CSV/train_clean.csv", row.names = FALSE)
write.csv(full, "Data/CSV/full.csv", row.names = FALSE)
str(train)
# Goal:     (1) Construct basic randomForest models from the data
#           (2) Select the best model (Model selection)
#           (3) Save a prediction with our best randomForest
library(randomForest)
library(plyr)
# Load in the cleaned data sets
load("Data/train_clean.RData")  # 891 obs
load("Data/test_clean.RData")   # 418 obs
###
### Create randomForest model
###
# Create random forest based on PCLASS, SEX, and FARE
forest <- randomForest(survived ~ sex + pclass + fare + age + fare_distance,
data = train, ntree = 15000, importance = TRUE)
# Goal: (1) Combine our three models into one prediction:
#             - randomForest
#             - SVM
#             - probit
# Source our models
source("2-randomForest.R")
source("3-SVM.R")
source("4-probit.R")
###
### Gather predictions
###
# randomForest
test$survived_rf <- predict(forest, test)
# SVM
test$survived_svm <- predict(svm.model, test, type = "response")
# Probit
test$survived_probit <- predict(probit, test)
test$survived_probit[test$survived >= 0.5] <- 2
test$survived_probit[test$survived < 0.5] <- 1
###
### Combine Predictions
###
combined <- as.numeric(test$survived_rf) +
as.numeric(test$survived_svm) +
as.numeric(test$survived_probit)
# 3 is 0
# 4 is 0
# 5 is 1
# 6 is 1
combined[combined <= 4] <- 0
combined[combined >= 5] <- 1
# Make our ensamble prediction
test$survived <- combined
write.csv(test, "Submissions/ensemble-03.csv")
# Goal: (1) Combine our three models into one prediction:
#             - randomForest
#             - SVM
#             - probit
# Source our models
source("2-randomForest.R")
source("3-SVM.R")
source("4-probit.R")
###
### Gather predictions
###
# randomForest
test$survived_rf <- predict(forest, test)
# SVM
test$survived_svm <- predict(svm.model, test, type = "response")
# Probit
test$survived_probit <- predict(probit, test)
test$survived_probit[test$survived >= 0.5] <- 2
test$survived_probit[test$survived < 0.5] <- 1
###
### Combine Predictions
###
combined <- as.numeric(test$survived_rf) +
as.numeric(test$survived_svm) +
as.numeric(test$survived_probit)
# 3 is 0
# 4 is 0
# 5 is 1
# 6 is 1
combined[combined <= 4] <- 0
combined[combined >= 5] <- 1
# Make our ensamble prediction
test$survived <- combined
write.csv(test, "Submissions/ensemble-03.csv")
?neuralnet
# Goal:     (1) Construct basic randomForest models from the data
#           (2) Select the best model (Model selection)
#           (3) Save a prediction with our best randomForest
library(neuralnet)
library(plyr)
# Load in the cleaned data sets
load("Data/train_clean.RData")  # 891 obs
load("Data/test_clean.RData")   # 418 obs
###
### Create randomForest model
###
# Create random forest based on PCLASS, SEX, and FARE
net <- neuralnet(survived ~ sex + pclass + fare + age, data = train,
ntree = 15000, importance = TRUE)
net <- neuralnet(survived ~ sex + pclass + fare + age, data = train)
