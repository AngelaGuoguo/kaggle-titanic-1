test$embarked <- factor(test$embarked)
###
### Fixing missing values
###
# 177 missing ages in TRAIN
# 86 missing ages in TEST
# 1 missing fare in TEST
# 2 missing embarked in TRAIN
# Combine the data sets for age/fare modeling
full <- join(test, train, type = "full")
# Multiple Imputation
#library(mi)
#inf <- mi.info(train)
#imp <- mi(train, info = inf, check.coef.convergence = FALSE, n.imp = 2, n.iter = 6, seed = 111)
#plot(imp)
# Create LM models for predicting missing values in AGE and FARE
age.mod <- lm(age ~ pclass + sex +
sibsp + parch + fare, data = full)
fare.mod<- lm(fare ~ pclass + sex +
sibsp + parch + age, data = full)
# Replace missing values in AGE and FARE with prediction
train$age[is.na(train$age)] <- predict(age.mod, train)[is.na(train$age)]
test$age[is.na(test$age)] <- predict(age.mod, test)[is.na(test$age)]
test$fare[is.na(test$fare)] <- predict(fare.mod, test)[is.na(test$fare)]
# Random Forest to find missing values
#full.age <- full[!is.na(full$age), ]  # Remove NA's
#full.age$fare[is.na(full.age$fare)] <- predict(fare.mod, full.age)[is.na(full.age$fare)]
#age.rf <- randomForest(age ~ pclass + sex + sibsp + parch + fare, data = full.age, ntree = 15000)
#train$age[is.na(train$age)] <- predict(age.rf, train)[is.na(train$age)]
#test$age[is.na(test$age)] <- predict(age.rf, test)[is.na(test$age)]
# Replace missing values in embarked with most popular
train$embarked[train$embarked == ""] <- "S"
train$embarked <- factor(train$embarked)
###
### Create "sex.name" variable"
###
library(stringr)
train$sex.name <- 0
test$sex.name <- 0
train$sex.name[!is.na(str_extract(train$name, "Mr"))] <- "Mr"
train$sex.name[!is.na(str_extract(train$name, "Mrs"))] <- "Mrs"
train$sex.name[!is.na(str_extract(train$name, "Mme"))] <- "Mrs"
train$sex.name[!is.na(str_extract(train$name, "Miss"))] <- "Miss"
train$sex.name[!is.na(str_extract(train$name, "Ms"))] <- "Miss"
train$sex.name[!is.na(str_extract(train$name, "Mlle"))] <- "Miss"
train$sex.name[!is.na(str_extract(train$name, "Capt"))] <- "Mr"
train$sex.name[!is.na(str_extract(train$name, "Major"))] <- "Mr"
train$sex.name[!is.na(str_extract(train$name, "Col"))] <- "Mr"
train$sex.name[!is.na(str_extract(train$name, "Master"))] <- "Mr"
train$sex.name[!is.na(str_extract(train$name, "Rev"))] <- "Mr"
train$sex.name[!is.na(str_extract(train$name, "Dr"))] <- "Mr"
train$sex.name[!is.na(str_extract(train$name, "Don"))] <- "Mr"
train$sex.name[!is.na(str_extract(train$name, "Countess"))] <- "Mrs"
train$sex.name[!is.na(str_extract(train$name, "Jonkheer"))] <- "Mr"
test$sex.name[!is.na(str_extract(test$name, "Mr"))] <- "Mr"
test$sex.name[!is.na(str_extract(test$name, "Mrs"))] <- "Mrs"
test$sex.name[!is.na(str_extract(test$name, "Mme"))] <- "Mrs"
test$sex.name[!is.na(str_extract(test$name, "Miss"))] <- "Miss"
test$sex.name[!is.na(str_extract(test$name, "Ms"))] <- "Miss"
test$sex.name[!is.na(str_extract(test$name, "Mlle"))] <- "Miss"
test$sex.name[!is.na(str_extract(test$name, "Capt"))] <- "Mr"
test$sex.name[!is.na(str_extract(test$name, "Major"))] <- "Mr"
test$sex.name[!is.na(str_extract(test$name, "Col"))] <- "Mr"
test$sex.name[!is.na(str_extract(test$name, "Master"))] <- "Mr"
test$sex.name[!is.na(str_extract(test$name, "Rev"))] <- "Mr"
test$sex.name[!is.na(str_extract(test$name, "Dr"))] <- "Mr"
test$sex.name[!is.na(str_extract(test$name, "Don"))] <- "Mr"
test$sex.name[!is.na(str_extract(test$name, "Countess"))] <- "Mrs"
test$sex.name[!is.na(str_extract(test$name, "Jonkheer"))] <- "Mr"
test$name[test$sex.name == 0]
train$name[train$sex.name == 0]
train$sex.name <- factor(train$sex.name)
test$sex.name <- factor(test$sex.name)
###
### Create "fare-distance" variable
###
# fare-distance = fare - mean(fare of pclass)
# Are those who pay less than the average for a ticket less likely to survive?
# Find the mean fare for each pclass
class1 <- subset(full, pclass == 1)
class2 <- subset(full, pclass == 2)
class3 <- subset(full, pclass == 3)
fare1 <- mean(class1$fare, na.rm = TRUE)
fare2 <- mean(class2$fare, na.rm = TRUE)
fare3 <- mean(class3$fare, na.rm = TRUE)
# Create fare_avg column
train$fare_avg[train$pclass == 1] <- fare1
train$fare_avg[train$pclass == 2] <- fare2
train$fare_avg[train$pclass == 3] <- fare3
test$fare_avg[test$pclass == 1] <- fare1
test$fare_avg[test$pclass == 2] <- fare2
test$fare_avg[test$pclass == 3] <- fare3
# Create fare-distance metric for Train
train <- transform(train, fare.distance = fare - fare_avg)
train <- train[, !names(train) %in% c("fare_avg")]
# Create fare-distance metric for Test
test <- transform(test, fare.distance = fare - fare_avg)
test <- test[, !names(test) %in% c("fare_avg")]
###
### Add family column
###
train$family <- NA
test$family <- NA
train$family[which(train$sibsp != 0 | train$parch != 0)] <- 1
train$family[which(train$sibsp == 0 & train$parch == 0)] <- 0
test$family[which(test$sibsp != 0 | test$parch != 0)] <- 1
test$family[which(test$sibsp == 0 & test$parch == 0)] <- 0
test$family <- factor(test$family)
train$family <- factor(train$family)
###
### Saving new data sets
###
# Save files as RData in order to preserve data structures
# Open .RData with load()
save("test", file = "Data/test_clean.RData")
save("train", file = "Data/train_clean.RData")
# Save as ARFF for WEKA using foreign
write.arff(test, file = "Data/test_clean.ARFF")
write.arff(train, file = "Data/train_clean.ARFF")
# Also save .csv's just in case. These do not preserve data structures,
# so don't use them in the analysis!
write.csv(test, "Data/CSV/test_clean.csv", row.names = FALSE)
write.csv(train, "Data/CSV/train_clean.csv", row.names = FALSE)
write.csv(full, "Data/CSV/full.csv", row.names = FALSE)
source("bdt.R")
install.package('C50')
install.packages('C50')
source("bdt.R")
train_error(survived_pred)
cv_kfolds(model, k = 9)
predict(boosted2, test)
# Goal: (1) Combine our three models into one prediction:
#             - randomForest
#             - SVM
#             - probit
# Source our data and clean it
source("1-clean.R")
# Source our models
source("2-randomForest.R")
source("3-SVM.R")
source("bdt.R")
###
### Gather predictions
###
# randomForest
test$survived_rf <- predict(forest, test)
# SVM
test$survived_svm <- predict(svm.model, test, type = "response")
# Neural Net
test$survived_bdt <- predict(boosted2, test)
###
### Combine Predictions
###
vote <- as.numeric(test$survived_rf) +
as.numeric(test$survived_svm) +
as.numeric(test$survived_bdt)
# 0 is 0
# 4 is 0
# 5 is 1
# 6 is 1
combined <- vote
combined[combined <= 4] <- 0
combined[combined >= 5] <- 1
# Make our ensamble prediction
test$survived <- combined
write.csv(test, "Submissions/ensemble-13.csv")
# Compare to highest
highest <- read.csv("Submissions/highest.csv")
which(test$survived != highest$survived)
# Goal: (1) Combine our three models into one prediction:
#             - randomForest
#             - SVM
#             - probit
# Source our data and clean it
source("1-clean.R")
# Source our models
source("2-randomForest.R")
source("3-SVM.R")
source("bdt.R")
###
### Gather predictions
###
# randomForest
test$survived_rf <- predict(forest, test)
# SVM
test$survived_svm <- predict(svm.model, test, type = "response")
# Neural Net
test$survived_bdt <- predict(boosted2, test)
###
### Combine Predictions
###
vote <- as.numeric(test$survived_rf) +
as.numeric(test$survived_svm) +
as.numeric(test$survived_bdt)
# 0 is 0
# 4 is 0
# 5 is 1
# 6 is 1
combined <- vote
combined[combined <= 4] <- 0
combined[combined >= 5] <- 1
# Make our ensamble prediction
test$survived <- combined
write.csv(test, "Submissions/ensemble-13.csv")
# Compare to highest
highest <- read.csv("Submissions/highest.csv")
which(test$survived != highest$survived)
# Goal: (1) Combine our three models into one prediction:
#             - randomForest
#             - SVM
#             - probit
# Source our data and clean it
source("1-clean.R")
# Source our models
source("2-randomForest.R")
source("3-SVM.R")
source("bdt.R")
###
### Gather predictions
###
# randomForest
test$survived_rf <- predict(forest, test)
# SVM
test$survived_svm <- predict(svm.model, test, type = "response")
# Neural Net
test$survived_bdt <- predict(boosted2, test)
###
### Combine Predictions
###
vote <- as.numeric(test$survived_rf) +
as.numeric(test$survived_svm) +
as.numeric(test$survived_bdt)
# 0 is 0
# 4 is 0
# 5 is 1
# 6 is 1
combined <- vote
combined[combined <= 4] <- 0
combined[combined >= 5] <- 1
# Make our ensamble prediction
test$survived <- combined
write.csv(test, "Submissions/ensemble-13.csv")
# Compare to highest
highest <- read.csv("Submissions/highest.csv")
which(test$survived != highest$survived)
source("bdt.R")
train_error(survived_pred)
cv_kfolds(model, k = 9)
###
### Boosted Decision Trees
###
library(gbm)
library(plyr)
library(ada)
library(caret)
library(C50)
# Load in the cleaned data sets
load("Data/train_clean.RData")  # 891 obs
load("Data/test_clean.RData")   # 418 obs
###
### Create data model
###
boosted <- ada(survived ~ sex + pclass + age + fare, data = train)
boosted2 <- ada(survived ~ sex.name + pclass + age + fare + family,
data = train, iter = 10000)
###
### Logit model
###
library(plyr)
# Load in the cleaned data sets
load("Data/train_clean.RData")  # 891 obs
load("Data/test_clean.RData")   # 418 obs
###
### Create probit model and make prediction
###
# Create probit with SEX, PCLASS, FARE, and AGE
probit <- glm(survived ~ sex.name + pclass + age + fare, data = train,
family = binomial(link = "logit"))
summary(probit)
model <- 'glm(survived ~ sex.name + pclass + age + fare, data = train, family = binomial(link = "logit"))'
predict(logit, train, type = "response")
logit <- glm(survived ~ sex.name + pclass + age + fare, data = train,
family = binomial(link = "logit"))
summary(logit)
predict(logit, train, type = "response")
train$survived_pred <- predict(logit, train, type = "response")
train$survived_pred[train$survived_pred >= 0.5] <- 1
train$survived_pred[train$survived_pred < 0.5] <- 0
# Goal: (1) Combine our three models into one prediction:
#             - randomForest
#             - SVM
#             - probit
# Source our data and clean it
source("1-clean.R")
# Source our models
source("2-randomForest.R")
source("3-SVM.R")
source("4-logit.R")
###
### Gather predictions
###
# randomForest
test$survived_rf <- predict(forest, test)
# SVM
test$survived_svm <- predict(svm.model, test, type = "response")
# Neural Net
test$survived_logit <- predict(logit, test, type = "response")
test$survived_logit[test$survived_logit >= 0.5] <- 1
test$survived_logit[test$survived_logit < 0.5] <- 0
###
### Combine Predictions
###
vote <- as.numeric(test$survived_rf) +
as.numeric(test$survived_svm) +
as.numeric(test$survived_bdt)
vote
vote <- as.numeric(test$survived_rf) +
as.numeric(test$survived_svm) +
as.numeric(test$survived_logit)
vote
as.numeric(test$survived_logit)
as.numeric(test$survived_svm)
###
### Logit model
###
# Load in the cleaned data sets
load("Data/train_clean.RData")  # 891 obs
load("Data/test_clean.RData")   # 418 obs
###
### Create probit model and make prediction
###
# Create probit with SEX, PCLASS, FARE, and AGE
logit <- glm(survived ~ sex.name + pclass + age + fare, data = train,
family = binomial(link = "logit"))
summary(logit)
# Save model as string
model <- 'glm(survived ~ sex.name + pclass + age + fare, data = train, family = binomial(link = "logit"))'
###
### Saving our model and prediction as a new CSV
###
# Make our prediction on the TRAIN data set [For calculating error]
train$survived_pred <- predict(logit, train, type = "response")
train$survived_pred[train$survived_pred >= 0.5] <- 1
train$survived_pred[train$survived_pred < 0.5] <- 0
# Make a prediction with our probit on TEST
test$survived <- predict(logit, test, type = "response")
test$survived[test$survived >= 0.5] <- 1
test$survived[test$survived < 0.5] <- 0
# save csv file for submission
write.csv(test, "Submissions/logit-01.csv")
# Goal: (1) Combine our three models into one prediction:
#             - randomForest
#             - SVM
#             - probit
# Source our data and clean it
source("1-clean.R")
# Source our models
source("2-randomForest.R")
source("3-SVM.R")
source("4-logit.R")
###
### Gather predictions
###
# randomForest
test$survived_rf <- predict(forest, test)
# SVM
test$survived_svm <- predict(svm.model, test, type = "response")
# Neural Net
test$survived_logit <- predict(logit, test, type = "response")
test$survived_logit[test$survived_logit >= 0.5] <- 2
test$survived_logit[test$survived_logit < 0.5] <- 1
###
### Combine Predictions
###
vote <- as.numeric(test$survived_rf) +
as.numeric(test$survived_svm) +
as.numeric(test$survived_logit)
# 0 is 0
# 4 is 0
# 5 is 1
# 6 is 1
combined <- vote
combined[combined <= 4] <- 0
combined[combined >= 5] <- 1
# Make our ensamble prediction
test$survived <- combined
write.csv(test, "Submissions/ensemble-14.csv")
# Compare to highest
highest <- read.csv("Submissions/highest.csv")
which(test$survived != highest$survived)
# Goal: (1) Combine our three models into one prediction:
#             - randomForest
#             - SVM
#             - probit
# Source our data and clean it
source("1-clean.R")
# Source our models
source("2-randomForest.R")
source("3-SVM.R")
source("4-logit.R")
###
### Gather predictions
###
# randomForest
test$survived_rf <- predict(forest, test)
# SVM
test$survived_svm <- predict(svm.model, test, type = "response")
# Neural Net
test$survived_logit <- predict(logit, test, type = "response")
test$survived_logit[test$survived_logit >= 0.8] <- 2
test$survived_logit[test$survived_logit < 0.8] <- 1
###
### Combine Predictions
###
vote <- as.numeric(test$survived_rf) +
as.numeric(test$survived_svm) +
as.numeric(test$survived_logit)
# 0 is 0
# 4 is 0
# 5 is 1
# 6 is 1
combined <- vote
combined[combined <= 4] <- 0
combined[combined >= 5] <- 1
# Make our ensamble prediction
test$survived <- combined
write.csv(test, "Submissions/ensemble-14.csv")
# Compare to highest
highest <- read.csv("Submissions/highest.csv")
which(test$survived != highest$survived)
# Goal: (1) Combine our three models into one prediction:
#             - randomForest
#             - SVM
#             - probit
# Source our data and clean it
source("1-clean.R")
# Source our models
source("2-randomForest.R")
source("3-SVM.R")
source("4-logit.R")
###
### Gather predictions
###
# randomForest
test$survived_rf <- predict(forest, test)
# SVM
test$survived_svm <- predict(svm.model, test, type = "response")
# Neural Net
test$survived_logit <- predict(logit, test, type = "response")
test$survived_logit[test$survived_logit >= 0.9] <- 2
test$survived_logit[test$survived_logit < 0.9] <- 1
###
### Combine Predictions
###
vote <- as.numeric(test$survived_rf) +
as.numeric(test$survived_svm) +
as.numeric(test$survived_logit)
# 0 is 0
# 4 is 0
# 5 is 1
# 6 is 1
combined <- vote
combined[combined <= 4] <- 0
combined[combined >= 5] <- 1
# Make our ensamble prediction
test$survived <- combined
write.csv(test, "Submissions/ensemble-14.csv")
# Compare to highest
highest <- read.csv("Submissions/highest.csv")
which(test$survived != highest$survived)
# Goal: (1) Combine our three models into one prediction:
#             - randomForest
#             - SVM
#             - probit
# Source our data and clean it
source("1-clean.R")
# Source our models
source("2-randomForest.R")
source("3-SVM.R")
source("4-logit.R")
###
### Gather predictions
###
# randomForest
test$survived_rf <- predict(forest, test)
# SVM
test$survived_svm <- predict(svm.model, test, type = "response")
# Neural Net
test$survived_logit <- predict(logit, test, type = "response")
test$survived_logit[test$survived_logit >= 0.8] <- 2
test$survived_logit[test$survived_logit < 0.8] <- 1
###
### Combine Predictions
###
vote <- as.numeric(test$survived_rf) +
as.numeric(test$survived_svm) +
as.numeric(test$survived_logit)
# 0 is 0
# 4 is 0
# 5 is 1
# 6 is 1
combined <- vote
combined[combined <= 4] <- 0
combined[combined >= 5] <- 1
# Make our ensamble prediction
test$survived <- combined
write.csv(test, "Submissions/ensemble-14.csv")
# Compare to highest
highest <- read.csv("Submissions/highest.csv")
which(test$survived != highest$survived)
33  40  44  81  89 126 160 200 202 217 226 228 240 282 283 284 305 324 344 360 409 411 415
40  44  89  95 198 200 202 217 226 228 240 282 283 284 305 324 360 391 409 411 415
